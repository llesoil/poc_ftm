{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "from treelib import Node, Tree\n",
    "from tree_sitter import Language, Parser\n",
    "import os\n",
    "import re\n",
    "import json\n",
    "import numpy as np\n",
    "\n",
    "if not os.path.isdir('./tree-sitter-go'):\n",
    "    print(\"Cloning https://github.com/tree-sitter/tree-sitter-go\")\n",
    "    os.system(\"git clone https://github.com/tree-sitter/tree-sitter-go\")\n",
    "            \n",
    "Language.build_library('build/my-languages.so', ['tree-sitter-go'])\n",
    "GO_LANGUAGE = Language('build/my-languages.so', 'go')\n",
    "parser = Parser()\n",
    "parser.set_language(GO_LANGUAGE)\n",
    "\n",
    "class ToggleCatcher():\n",
    "    \n",
    "    def __init__(self, system_name):\n",
    "        \n",
    "        self.system_name = system_name\n",
    "        \n",
    "        # configuration file containing the json - see the HowTo.md \n",
    "        # to add your own configuration\n",
    "        self.config_file_path = \"./config/\"+self.system_name+'.json'\n",
    "        \n",
    "        # directory to export the results\n",
    "        self.results_dir = \"./results/\"\n",
    "        \n",
    "        # inputs - properties of the current system\n",
    "        attributes = json.load(open(self.config_file_path))\n",
    "        ## directory in which the source code is located\n",
    "        ## e.g. \"./kops/\" for Kops\n",
    "        self.directory = attributes[\"directory\"]\n",
    "        ## if the directory of the system does not exist, we clone the repository\n",
    "        if not os.path.isdir(self.directory):\n",
    "            print(\"Cloning \"+attributes[\"url\"])\n",
    "            os.system(\"git clone \"+attributes[\"url\"])\n",
    "\n",
    "        ## if we have access to the keywords, we use them\n",
    "        if \"keywords\" in attributes:\n",
    "            self.keywords = [k.lower() for k in attributes[\"keywords\"]]\n",
    "        else:\n",
    "            ## else we find them with the regular expression\n",
    "            ## the file listing the Feature Toggles (FT) and their name \n",
    "            ## aka our keywords to search in the code\n",
    "            ## e.g. \"./kops/pkg/featureflag/featureflag.go\" for Kops\n",
    "            self.ft_file = attributes[\"ft_file\"]\n",
    "            ## the regular expression to use to find the names of FTs\n",
    "            ## e.g. \"[N|n]ew.*,*Bool*\" for Kops\n",
    "            self.reg_exp = attributes[\"reg_exp\"]\n",
    "            self.sep = None\n",
    "            if \"sep_reg_exp\" in attributes:\n",
    "                self.sep = attributes['sep_reg_exp']\n",
    "            self.keywords = self.get_ft_keywords()\n",
    "        ## the way ft are expressed in the code\n",
    "        ## depends on the library used by the developers\n",
    "        ## e.g. \"featureflag.\" for Kops\n",
    "        self.feature_structure = attributes[\"feature_structure\"]\n",
    "        \n",
    "        # outputs - measures on the system\n",
    "        ## counts the number of files with FT\n",
    "        self.count_file = dict()\n",
    "        ## counts the occurrences of FTs in the files\n",
    "        self.occurences = dict()\n",
    "        ## lists keywords per file\n",
    "        self.kw_file = dict()\n",
    "        ## the resulting list of interesting statements\n",
    "        self.statements = []\n",
    "        ## initialize the dicts\n",
    "        for kw in sorted(self.keywords):\n",
    "            self.count_file[kw] = 0\n",
    "            self.occurences[kw] = 0\n",
    "        \n",
    "        # files with fts\n",
    "        self.file_interests = self.list_kw_files()\n",
    "        \n",
    "        # launches an analyse\n",
    "        self.analyse_all_files()\n",
    "\n",
    "    def get_ft_keywords(self):\n",
    "        ## output : search keywords in the file self.ft_file containing all the feature toggles\n",
    "        ## uses the regular_expression self.reg_exp to search in the file\n",
    "        \n",
    "        with open(self.ft_file, 'r') as f:\n",
    "            catch_feat = re.findall(self.reg_exp, f.read())\n",
    "        \n",
    "        if self.sep:\n",
    "            keywords = [feature.split(self.sep)[1] for feature in catch_feat]\n",
    "        else:\n",
    "            keywords = [feature for feature in catch_feat]\n",
    "\n",
    "        return [k.lower() for k in keywords]\n",
    "    \n",
    "    def list_kw_files(self):\n",
    "        ### output : lists the files with feature toggles based on the self.keywords list of FTs\n",
    "        \n",
    "        go_folders = [x[0] for x in os.walk(self.directory)]\n",
    "\n",
    "        go_files = []\n",
    "        for dir_name in go_folders:\n",
    "            files = [dir_name+\"/\"+k for k in os.listdir(dir_name) if k[len(k)-3:] ==\".go\"]\n",
    "            # '.go' could be an input the language in the next version in the configuration file\n",
    "            go_files.extend(files)\n",
    "\n",
    "        go_file_interests = []\n",
    "\n",
    "        for file in go_files:\n",
    "            s = \"\"\n",
    "            with open(file, \"r\") as f:\n",
    "                s+=f.read().lower()\n",
    "            kws = [k for k in self.keywords if k in s]\n",
    "            if len(kws) > 0 and self.feature_structure in s:\n",
    "                self.kw_file[file] = []\n",
    "                for k in kws:\n",
    "                    self.kw_file[file].append(k)\n",
    "                    self.count_file[k]+=1\n",
    "                    self.occurences[k]+=s.count(k)\n",
    "                go_file_interests.append(file)\n",
    "\n",
    "        return go_file_interests\n",
    "\n",
    "    \n",
    "    def get_code(self, node):\n",
    "        ### input : a node of the ast\n",
    "        ### output : get the \"code\" of the node of the ast, \n",
    "        ### i.e. the string content of the related part in the code\n",
    "        \n",
    "        code = self.source[node.start_byte:node.end_byte].decode('utf8').lower()\n",
    "        code = code.replace('\\n', '').replace('\\t','')\n",
    "        return code\n",
    "\n",
    "    \n",
    "    def get_id(self, node):\n",
    "        ### input : a node of the ast\n",
    "        ### output : get the \"code\" of the node, i.e. the related part of the code\n",
    "        \n",
    "        node_type = node.type\n",
    "        if node_type not in self.type_nodes:\n",
    "            self.type_nodes[node_type]=1\n",
    "        else:\n",
    "            self.type_nodes[node_type]+=1\n",
    "        return node_type+str(self.type_nodes[node_type])\n",
    "\n",
    "    \n",
    "    def process_node(self, root_id, node):\n",
    "        ### input : a parent node and a child node\n",
    "        ### output : analysis of the parent and starts the analyses of the grandchildren\n",
    "        ### works recursively\n",
    "        ### analyse = isolates the conditions of the if statements containing at least one feature toggle\n",
    "        ### @Aaron to replace with your code when you have the time\n",
    "        \n",
    "        node_id = self.get_id(node)\n",
    "        node_content = self.get_code(node)\n",
    "        for kw in self.keywords:\n",
    "            if kw in node_content and node.type == 'if_statement':\n",
    "                for c in node.children:\n",
    "                    if c.type in ['binary_expression', 'unary_expression', 'call_expression']:\n",
    "                        final_code = self.get_code(c)\n",
    "                        if self.feature_structure in final_code:\n",
    "                            self.statements.append(final_code)\n",
    "        if len(node.children) != 0:\n",
    "            for i in range(len(node.children)):\n",
    "                self.process_node(node_id, node.children[i])\n",
    "    \n",
    "    \n",
    "    def analyse_file(self, filename):\n",
    "        ### input : a filename\n",
    "        ### output: process the ast of one file\n",
    "        \n",
    "        s = \"\"\n",
    "        with open(filename, \"r\") as f:\n",
    "            s+=f.read()+\"\\n\"\n",
    "        s = s.lower()\n",
    "\n",
    "        self.source = bytes(s, \"utf8\")\n",
    "        ast = parser.parse(self.source)\n",
    "\n",
    "        root_node = ast.root_node\n",
    "\n",
    "        self.type_nodes = dict()\n",
    "\n",
    "        for i in range(len(root_node.children)):\n",
    "            self.process_node(\"root\", root_node.children[i])\n",
    "    \n",
    "    def analyse_all_files(self):\n",
    "        ### output : analyse all the .go files of the project\n",
    "        ### and put the results in self.statements\n",
    "        \n",
    "        for fi in self.file_interests:\n",
    "            self.analyse_file(fi)\n",
    "            \n",
    "    def export_results(self):\n",
    "        #### output: export results to the ./results dir\n",
    "        print(\"------\\nExporting\", system, \"results\\n------\")\n",
    "        print(\"Saving statements to \", \n",
    "              self.results_dir+\"statements/\"+system+\".txt\")\n",
    "        np.savetxt(self.results_dir+\"statements/\"+self.system_name+\".txt\", \n",
    "                   self.statements, fmt=\"%s\", delimiter=\"\\n\")\n",
    "        print(\"Saving other results to \", \n",
    "              self.results_dir+'kw_file/'+self.system_name+'.json',\n",
    "              self.results_dir+'occurences/'+self.system_name+'.json',\n",
    "              self.results_dir+'count_file/'+self.system_name+'.json')\n",
    "        with open(self.results_dir+'kw_file/'+self.system_name+'.json', \"w\") as outfile:\n",
    "            json.dump(tc.kw_file, outfile)\n",
    "        with open(self.results_dir+'occurences/'+self.system_name+'.json', \"w\") as outfile:\n",
    "            json.dump(tc.occurences, outfile)\n",
    "        with open(self.results_dir+'count_file/'+self.system_name+'.json', \"w\") as outfile:\n",
    "            json.dump(tc.count_file, outfile)\n",
    "        print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------\n",
      "Exporting boulder results\n",
      "------\n",
      "Saving statements to  ./results/statements/boulder.txt\n",
      "Saving other results to  ./results/kw_file/boulder.json ./results/occurences/boulder.json ./results/count_file/boulder.json\n",
      "\n",
      "\n",
      "------\n",
      "Exporting client results\n",
      "------\n",
      "Saving statements to  ./results/statements/client.txt\n",
      "Saving other results to  ./results/kw_file/client.json ./results/occurences/client.json ./results/count_file/client.json\n",
      "\n",
      "\n",
      "------\n",
      "Exporting juju results\n",
      "------\n",
      "Saving statements to  ./results/statements/juju.txt\n",
      "Saving other results to  ./results/kw_file/juju.json ./results/occurences/juju.json ./results/count_file/juju.json\n",
      "\n",
      "\n",
      "Cloning https://github.com/kubernetes/kops\n",
      "------\n",
      "Exporting kops results\n",
      "------\n",
      "Saving statements to  ./results/statements/kops.txt\n",
      "Saving other results to  ./results/kw_file/kops.json ./results/occurences/kops.json ./results/count_file/kops.json\n",
      "\n",
      "\n",
      "Cloning https://github.com/kubernetes/kubernetes\n",
      "------\n",
      "Exporting kubernetes results\n",
      "------\n",
      "Saving statements to  ./results/statements/kubernetes.txt\n",
      "Saving other results to  ./results/kw_file/kubernetes.json ./results/occurences/kubernetes.json ./results/count_file/kubernetes.json\n",
      "\n",
      "\n",
      "Cloning https://github.com/loomnetwork/loomchain\n",
      "------\n",
      "Exporting loomchain results\n",
      "------\n",
      "Saving statements to  ./results/statements/loomchain.txt\n",
      "Saving other results to  ./results/kw_file/loomchain.json ./results/occurences/loomchain.json ./results/count_file/loomchain.json\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "config_dir = \"./config/\"\n",
    "\n",
    "for config_file in sorted(os.listdir(config_dir)):\n",
    "    system = config_file[:-5]\n",
    "    tc = ToggleCatcher(system)\n",
    "    tc.export_results()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
